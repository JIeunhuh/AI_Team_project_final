{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 및 파일 이름 설정\n",
    "annotation_dir = \"../img_test_08/\"\n",
    "\n",
    "image_dir = \"../img_test_08/AI_Result_img\"\n",
    "output_dir = \"../img_test_08/Reshaped_img\"\n",
    "\n",
    "test_image_name_dir = \"../img_test_08/test_image_list.txt\"\n",
    "train_image_name_dir = \"../img_test_08/train_image_list.txt\"\n",
    "caption_file = \"../img_test_08/test07caption.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 갯수 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴더 '../img_test_08/AI_Result_img' 내에 152 개의 이미지 파일이 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 폴더 내의 이미지 파일 목록 가져오기\n",
    "image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "\n",
    "# 이미지 파일의 확장자를 확인하고 갯수 counting\n",
    "image_extensions = ['.jpg', '.jpeg', '.png']\n",
    "image_count = sum(1 for f in image_files if any(f.endswith(ext) for ext in image_extensions))\n",
    "\n",
    "print(f\"폴더 '{image_dir}' 내에 {image_count} 개의 이미지 파일이 있습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m output_image_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, image_name)\n\u001b[0;32m     47\u001b[0m \u001b[39m# 배경 제거 및 노이즈 제거 적용\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m remove_background(input_image_path, \u001b[39m\"\u001b[39;49m\u001b[39mtemp_image.png\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     49\u001b[0m remove_noise(\u001b[39m\"\u001b[39m\u001b[39mtemp_image.png\u001b[39m\u001b[39m\"\u001b[39m, output_image_path)\n\u001b[0;32m     51\u001b[0m \u001b[39m# 임시 이미지 파일 삭제\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m, in \u001b[0;36mremove_background\u001b[1;34m(input_image_path, output_image_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m rect \u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, image\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], image\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[39m# GrabCut 알고리즘 적용\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m cv2\u001b[39m.\u001b[39;49mgrabCut(image, mask, rect, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m5\u001b[39;49m, cv2\u001b[39m.\u001b[39;49mGC_INIT_WITH_RECT)\n\u001b[0;32m     14\u001b[0m \u001b[39m# 결과 마스크 생성\u001b[39;00m\n\u001b[0;32m     15\u001b[0m mask2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere((mask \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m|\u001b[39m (mask \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m), \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n"
     ]
    }
   ],
   "source": [
    "# 배경 제거 함수 정의 (예: GrabCut 알고리즘 사용)\n",
    "def remove_background(input_image_path, output_image_path):\n",
    "    image = cv2.imread(input_image_path)\n",
    "    \n",
    "    # 초기 마스크 생성\n",
    "    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "\n",
    "    # 객체를 둘러싸는 직사각형 경계 상자 정의 (예: 이미지 전체)\n",
    "    rect = (0, 0, image.shape[1], image.shape[0])\n",
    "\n",
    "    # GrabCut 알고리즘 적용\n",
    "    cv2.grabCut(image, mask, rect, None, None, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "    # 결과 마스크 생성\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "    # 배경 제거된 이미지 생성\n",
    "    result_image = image * mask2[:, :, np.newaxis]\n",
    "    \n",
    "    cv2.imwrite(output_image_path, result_image)\n",
    "\n",
    "# 노이즈 제거 함수 정의 (예: 미디언 필터 사용)\n",
    "def remove_noise(input_image_path, output_image_path):\n",
    "    image = cv2.imread(input_image_path)\n",
    "    \n",
    "    # 미디언 필터 적용\n",
    "    result_image = cv2.medianBlur(image, 5)  # 필터 크기 조정 가능\n",
    "\n",
    "    cv2.imwrite(output_image_path, result_image)\n",
    "\n",
    "# 이미지 파일 이름을 가져오는 함수 정의\n",
    "def get_image_names(img_dir):\n",
    "    image_names = []\n",
    "    for filename in os.listdir(img_dir):\n",
    "        if filename.endswith(\".png\"):\n",
    "            image_names.append(filename)\n",
    "    return image_names\n",
    "\n",
    "# 이미지 파일 이름 리스트 가져오기\n",
    "image_names = get_image_names(image_dir)\n",
    "\n",
    "# 이미지 전처리 및 저장\n",
    "for image_name in image_names:\n",
    "    input_image_path = os.path.join(image_dir, image_name)\n",
    "    output_image_path = os.path.join(output_dir, image_name)\n",
    "\n",
    "    # 배경 제거 및 노이즈 제거 적용\n",
    "    remove_background(input_image_path, \"temp_image.png\")\n",
    "    remove_noise(\"temp_image.png\", output_image_path)\n",
    "\n",
    "    # 임시 이미지 파일 삭제\n",
    "    os.remove(\"temp_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caption 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일 리스트와 캡션 리스트 생성\n",
    "image_list = sorted(os.listdir(image_dir))\n",
    "captions = []\n",
    "\n",
    "with open(caption_file, \"r\") as file:\n",
    "    for line in file:\n",
    "        image_name, caption = line.strip().split(\"\\t\")[0], line.strip().split(\"\\t\")[1]\n",
    "        captions.append(caption)\n",
    "\n",
    "# Tokenizer를 사용하여 캡션 텍스트 토큰화\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(captions)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "sequences = tokenizer.texts_to_sequences(captions)\n",
    "\n",
    "# 시퀀스 패딩 (모든 시퀀스를 동일한 길이로 맞춤)\n",
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# 이미지 파일 이름과 정수 시퀀스를 매칭\n",
    "image_caption_map = dict(zip(image_list, sequences))\n",
    "\n",
    "# train, test 데이터 분리\n",
    "random.shuffle(image_list)\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(image_list))\n",
    "train_image_names = image_list[:split_index]\n",
    "test_image_names = image_list[split_index:]\n",
    "\n",
    "# train, test 데이터에 해당하는 캡션 리스트 생성\n",
    "train_captions = [image_caption_map[image_name] for image_name in train_image_names]\n",
    "test_captions = [image_caption_map[image_name] for image_name in test_image_names]\n",
    "\n",
    "# 이미지 파일 이름을 텍스트 파일로 저장하는 함수 정의\n",
    "def save_image_list(image_names, output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        for image_name in image_names:\n",
    "            file.write(image_name + '\\n')\n",
    "\n",
    "# 이미지 파일 이름을 각각의 텍스트 파일에 저장\n",
    "save_image_list(train_image_names, train_image_name_dir)\n",
    "save_image_list(test_image_names, test_image_name_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open(os.path.join(annotation_dir, file_name), 'rb') as file_handle:\n",
    "        file_lines = file_handle.read().splitlines()\n",
    "    return file_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 이미지 이름 불러오기\n",
    "train_image_paths = read_file('train_image_list.txt')\n",
    "test_image_paths = read_file('test_image_list.txt')\n",
    "captions = read_file('test07caption.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "31\n",
      "760\n"
     ]
    }
   ],
   "source": [
    "print(len(train_image_paths))\n",
    "print(len(test_image_paths))\n",
    "print(len(captions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_get_vocab():\n",
    "    image_caption_map = {}\n",
    "    unique_words = set()\n",
    "\n",
    "    max_words = 0\n",
    "\n",
    "    for caption in captions:\n",
    "        caption = caption.decode(\"utf-8\")\n",
    "        image_name = caption.split('#')[0]\n",
    "        image_caption = caption.split('#')[1].split('\\t')[1]\n",
    "\n",
    "        if image_name not in image_caption_map:\n",
    "            image_caption_map[image_name] = [image_caption]\n",
    "        else:\n",
    "            image_caption_map[image_name].append(image_caption)\n",
    "\n",
    "        caption_words = image_caption.split()\n",
    "        max_words = max(max_words, len(caption_words))\n",
    "        unique_words.update(caption_words)\n",
    "\n",
    "    unique_words = list(unique_words)\n",
    "    word_to_index_map = {word: index for index, word in enumerate(unique_words)}\n",
    "    index_to_word_map = {index: word for index, word in enumerate(unique_words)}\n",
    "\n",
    "    return image_caption_map, max_words, unique_words, word_to_index_map, index_to_word_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModel:\n",
    "    def __init__(self):\n",
    "        vgg_model = VGG16(weights='imagenet', include_top=True)\n",
    "        self.model = Model(inputs=vgg_model.input,\n",
    "                           outputs=vgg_model.get_layer('fc2').output)\n",
    "\n",
    "    # 이미지 읽어 들여 전처리하는 매서드\n",
    "    @staticmethod\n",
    "    def load_preprocess_image(image_path):\n",
    "        image_array = load_img(image_path, target_size=(224, 224))\n",
    "        image_array = img_to_array(image_array)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        image_array = preprocess_input(image_array)\n",
    "        return image_array\n",
    "\n",
    "    # 이미지를 로딩하여 예측하는 매서드\n",
    "    def extract_feature_from_image_path(self, image_path):\n",
    "        image_array = self.load_preprocess_image(image_path)\n",
    "        features = self.model.predict(image_array)\n",
    "        return features.reshape((4096, 1))\n",
    "\n",
    "    # 이미지 경로를 포함한 리스트를 따라가며 특징 리스트 생성 매서드\n",
    "    def extract_feature_from_image_paths(self, work_dir, image_names):\n",
    "        features = []\n",
    "        for image_name in image_names:\n",
    "            image_path = os.path.join(work_dir, image_name)\n",
    "            feature = self.extract_feature_from_image_path(image_path)\n",
    "            features.append(feature)\n",
    "        return features\n",
    "\n",
    "    # 추출한 특징을 pickle 파일로 저장 매서드\n",
    "    def extract_features_and_save(self, work_dir, image_names, file_name):\n",
    "        features = self.extract_feature_from_image_paths(work_dir, image_names)\n",
    "        with open(file_name, 'wb') as p:\n",
    "            pickle.dump(features, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467096/553467096 [==============================] - 50s 0us/step\n",
      "1/1 [==============================] - 1s 956ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 278ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 272ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 276ms/step\n"
     ]
    }
   ],
   "source": [
    "# trian, test 이미지 특징 추출\n",
    "I = ImageModel()\n",
    "\n",
    "I.extract_features_and_save(b'../img_test_08/AI_Result_img',train_image_paths, 'train_image_features.p')\n",
    "I.extract_features_and_save(b'../img_test_08/AI_Result_img',test_image_paths, 'test_image_features.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../img_test_08/train_image_features.p', 'rb') as p:\n",
    "      train_ds = pickle.load(p)\n",
    "with open('../img_test_08/test_image_features.p', 'rb') as p:\n",
    "      test_ds = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.6050958]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.34871292],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.0886719 ],\n",
      "       [0.381657  ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.5233148],\n",
      "       [1.901562 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.8247345],\n",
      "       [1.0853554]], dtype=float32), array([[0.        ],\n",
      "       [1.3335574 ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.5466149 ],\n",
      "       [0.15384722]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.9094123],\n",
      "       [1.7897921]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.12927973],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.8840879 ],\n",
      "       [0.64098513]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.32162064]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.8909081],\n",
      "       [1.268358 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [3.2995882]], dtype=float32), array([[0.      ],\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       ...,\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       [2.697083]], dtype=float32), array([[0.        ],\n",
      "       [0.15847346],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.5801158 ],\n",
      "       [0.6710942 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [3.0426354],\n",
      "       [0.3239834]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.0735419],\n",
      "       [1.3636308]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.01670688],\n",
      "       [2.818823  ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.6069732],\n",
      "       [1.458808 ]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [2.2367046],\n",
      "       [1.1753998]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.68821084],\n",
      "       [0.8336685 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.7440161]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [2.5270293]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.96201116]], dtype=float32), array([[0.       ],\n",
      "       [0.8871912],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [3.691482 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [1.6876533]], dtype=float32), array([[0.       ],\n",
      "       [0.6869801],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.5961518]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.5332952],\n",
      "       [3.2414405]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.5609201]], dtype=float32), array([[0.42121816],\n",
      "       [0.        ],\n",
      "       [2.47057   ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.37107423]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [3.9902463]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.46939334]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.40978128],\n",
      "       [2.1318264 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.9738418],\n",
      "       [1.5309426]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [1.8069203]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [2.7357485]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.4768298],\n",
      "       [0.6468014]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.        ],\n",
      "       [0.48022428],\n",
      "       [1.4883437 ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.01382676],\n",
      "       [0.32984075]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.0887754],\n",
      "       [2.01615  ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [2.7898316]], dtype=float32), array([[0.        ],\n",
      "       [1.6944486 ],\n",
      "       [0.05025655],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [2.897228  ],\n",
      "       [1.981741  ]], dtype=float32), array([[0.      ],\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       ...,\n",
      "       [0.      ],\n",
      "       [0.797103],\n",
      "       [3.181251]], dtype=float32), array([[1.3223944 ],\n",
      "       [0.        ],\n",
      "       [0.86543417],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [2.035312  ],\n",
      "       [3.2071037 ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.2682618 ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.79711586],\n",
      "       [0.27467963]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [3.7458618]], dtype=float32), array([[0.       ],\n",
      "       [1.1681064],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [1.6281221]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.43998185],\n",
      "       [0.88430744]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.        ],\n",
      "       [0.32223737],\n",
      "       [0.8341764 ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.6655443 ],\n",
      "       [0.17969954]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [2.2728794],\n",
      "       [1.1761122]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.1737683],\n",
      "       [1.1020573]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.5538416],\n",
      "       [1.3352444]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [1.2020493]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.8201663],\n",
      "       [1.318935 ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.76920336]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.1895123],\n",
      "       [1.7118096]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.6271155],\n",
      "       [1.0319041]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [1.8574786]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [1.3659322]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.99618286],\n",
      "       [2.0881493 ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.04745704],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.5548698 ],\n",
      "       [0.33448178]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.        ],\n",
      "       [0.15751156],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.3975105 ],\n",
      "       [0.7173853 ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.6661259 ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.131756  ],\n",
      "       [0.19158834]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.       ],\n",
      "       [1.250081 ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.814331 ],\n",
      "       [1.3236747]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.9992983],\n",
      "       [1.6683676]], dtype=float32), array([[0.        ],\n",
      "       [0.75553656],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.0279794 ],\n",
      "       [2.1154828 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [3.8520565]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.7937424],\n",
      "       [1.1720328]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.26080978],\n",
      "       [2.926514  ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.8635781],\n",
      "       [1.0333756]], dtype=float32), array([[0.        ],\n",
      "       [0.58309793],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.7920293 ],\n",
      "       [1.3350503 ]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [3.4741218]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.5907654],\n",
      "       [1.6257018]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.4130757],\n",
      "       [0.4550919]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.37350923]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [3.6073463]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.09251851],\n",
      "       [0.        ],\n",
      "       [0.        ]], dtype=float32), array([[0.       ],\n",
      "       [0.1762096],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.8490797],\n",
      "       [1.1370142]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.1774629],\n",
      "       [0.       ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.8348658 ],\n",
      "       [0.03570831]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.38658506],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.5059644 ],\n",
      "       [0.        ]], dtype=float32), array([[0.        ],\n",
      "       [0.98462975],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [1.978209  ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [2.252516 ],\n",
      "       [3.1085684]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.3596178 ],\n",
      "       [0.47892332]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.1972129 ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.8232865 ],\n",
      "       [0.60144246]], dtype=float32), array([[0.       ],\n",
      "       [0.242069 ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.5467621],\n",
      "       [1.8658314]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.12338662]], dtype=float32), array([[0.      ],\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       ...,\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       [3.434891]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.26938012],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [1.4305893 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.2074842],\n",
      "       [2.0729032]], dtype=float32), array([[0.       ],\n",
      "       [0.3569584],\n",
      "       [0.1270253],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [2.052099 ],\n",
      "       [1.8385391]], dtype=float32), array([[0.       ],\n",
      "       [0.4117954],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.4175374],\n",
      "       [0.       ]], dtype=float32), array([[0.      ],\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       ...,\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       [0.636826]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.6401019],\n",
      "       [1.5719197]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.35059258],\n",
      "       [1.2447543 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.3085046],\n",
      "       [2.5661366]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.28359598],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.1590934 ],\n",
      "       [0.9731796 ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.34730548],\n",
      "       [0.        ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [1.8194215]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [1.2771037]], dtype=float32), array([[0.      ],\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       ...,\n",
      "       [0.      ],\n",
      "       [1.626102],\n",
      "       [2.469464]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.5420703],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.951249 ],\n",
      "       [0.5728667]], dtype=float32), array([[0.        ],\n",
      "       [0.01782164],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.6421599 ],\n",
      "       [0.32062116]], dtype=float32), array([[0.        ],\n",
      "       [0.8711252 ],\n",
      "       [0.08376819],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.37444806]], dtype=float32), array([[0.        ],\n",
      "       [0.16006923],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.3276343 ],\n",
      "       [0.10637897]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [2.2549415],\n",
      "       [1.9941225]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.2910187],\n",
      "       [1.2810154]], dtype=float32), array([[0.        ],\n",
      "       [0.14806491],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.5749547 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.6779895],\n",
      "       [2.214686 ]], dtype=float32), array([[0.        ],\n",
      "       [0.07080799],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.9617114 ]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.       ],\n",
      "       [1.3250148],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [2.136374 ]], dtype=float32), array([[0.        ],\n",
      "       [0.02437171],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.07627654],\n",
      "       [1.2241218 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.4967823],\n",
      "       [0.686694 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.218154 ],\n",
      "       [1.4080794]], dtype=float32), array([[0.      ],\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       ...,\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       [3.860805]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [2.4008107],\n",
      "       [1.977164 ]], dtype=float32)]\n",
      "----------------------------------------------------\n",
      "[array([[0.       ],\n",
      "       [0.6421475],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.6419077],\n",
      "       [0.9445181]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.35238668],\n",
      "       [1.0253935 ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.5976891 ],\n",
      "       [0.47478387]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [2.3728578 ],\n",
      "       [0.38613307]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.2924972],\n",
      "       [0.       ],\n",
      "       [0.       ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.7542554],\n",
      "       [2.025831 ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.8528811 ],\n",
      "       [0.26901567]], dtype=float32), array([[0.        ],\n",
      "       [0.06741041],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.17061341],\n",
      "       [0.        ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [3.3306472]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.24563196]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.1627352 ],\n",
      "       [0.94125533]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [1.9744886],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [2.7250826]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [2.286699 ],\n",
      "       [4.5018063]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.0283379],\n",
      "       [1.0336437]], dtype=float32), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       ...,\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.5994488],\n",
      "       [1.2114687]], dtype=float32), array([[0.2016949],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.4986501],\n",
      "       [1.499331 ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.15071142],\n",
      "       [1.6936591 ]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.9555461],\n",
      "       [1.0233319]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [0.0168815 ],\n",
      "       [0.81009936]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [2.0540938]], dtype=float32), array([[0.      ],\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       ...,\n",
      "       [0.      ],\n",
      "       [0.      ],\n",
      "       [2.458164]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.4088614 ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.1409438 ],\n",
      "       [0.67262197]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.4167581],\n",
      "       [2.6472173]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [1.4526131],\n",
      "       [0.910939 ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [1.6722903 ],\n",
      "       [0.22131476]], dtype=float32), array([[0.9876886],\n",
      "       [0.       ],\n",
      "       [1.1638402],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ]], dtype=float32), array([[0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       ...,\n",
      "       [0.        ],\n",
      "       [2.0055735 ],\n",
      "       [0.85258454]], dtype=float32), array([[0.       ],\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       ...,\n",
      "       [0.       ],\n",
      "       [0.       ],\n",
      "       [1.1637377]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(train_ds)\n",
    "print('----------------------------------------------------')\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_caption_map, max_words, unique_words, word_to_index_map, index_to_word_map = get_vocab()\n",
    "image_caption_map, max_words, unique_words, word_to_index_map, index_to_word_map = up_get_vocab()\n",
    "vocabulary_size = len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['startseq The absence of objects is conspicuous against the bright illumination that highlights the black background. endseq', 'startseq Dim lighting exposes the presence of a polluted white plastic background. endseq', 'startseq In the low light setting, there is a tainted white plastic surface. endseq', 'startseq A contaminated white plastic backdrop is visible in the dim light. endseq', 'startseq Under subdued lighting, a white plastic background is tainted. endseq']\n",
      "['startseq A paper with various colors printed on it is tied with a yellow rubber band on the white background. endseq', 'startseq Against the backdrop of white, a paper featuring a spectrum of printed colors is secured in place by a yellow rubber band. endseq', \"startseq Resting on the pristine white surface, you'll find a paper adorned with an array of colors, held together using a yellow rubber band. endseq\", 'startseq The white background serves as the canvas for a paper with diverse printed colors, fastened with a yellow rubber band. endseq', 'startseq Displayed on the white surface is a paper enriched with various colors in its print, bound together by a vibrant yellow rubber band. endseq']\n",
      "['startseq Several damaged papers with various colors printed on them and a damaged white vinyl are present on the white background in a low level of contamination. endseq', 'startseq On the white background, you can see a collection of papers displaying diverse colors, each with signs of damage, accompanied by a white vinyl also showing wear and tear, all in a state of mild contamination. endseq', 'startseq Resting against the white backdrop are several papers, each showcasing different colors yet bearing damage, along with a worn white vinyl, all exhibiting a slight level of contamination. endseq', 'startseq Displayed on the white surface are multiple papers featuring various colors and evident damage, alongside a damaged white vinyl, all showing a subtle degree of contamination. endseq', 'startseq The white background hosts a selection of papers with a range of colors, all displaying varying degrees of damage, along with a white vinyl that has also been affected, all in a state of minor contamination. endseq']\n",
      "['startseq There are no objects on the black plastic background. endseq', 'startseq The black plastic background is devoid of any objects. endseq', 'startseq No objects can be found on the black plastic backdrop. endseq', 'startseq The black plastic background is empty of objects. endseq', 'startseq There are no items on the black plastic background. endseq']\n",
      "['startseq A crumpled white paper cup holder and a crumpled vinyl with prints in various colors are present on a black background under bright lighting. endseq', 'startseq Resting against the dark backdrop of the black background, a crumpled white paper cup holder and a crumpled vinyl adorned with prints in diverse colors are illuminated by bright lighting. endseq', \"startseq Positioned on the black surface, you'll find a combination of a crumpled white paper cup holder and a crumpled vinyl displaying prints in various colors, both brought to life by intense lighting. endseq\", 'startseq The black background serves as a dramatic canvas for a scene featuring a crumpled white paper cup holder and a crumpled vinyl with multicolored prints, illuminated by the brilliance of bright lighting. endseq', 'startseq Displayed on the black background, a crumpled white paper cup holder and a crumpled vinyl featuring prints in various colors come alive under the luminosity of bright lighting. endseq']\n",
      "['startseq Cleaning a dirty white background by hand. endseq', 'startseq Under the subdued glow, there exists a tainted white plastic backdrop. endseq', 'startseq In dim lighting conditions, a contaminated white plastic surface is present. endseq', 'startseq A tainted white plastic background becomes apparent under low light. endseq', 'startseq Under the dimly lit environment, a contaminated white plastic backdrop exists. endseq']\n",
      "['startseq A paper with various colors printed on it is tied with a yellow rubber band on the white background. endseq', 'startseq Positioned on the white background, a paper featuring a variety of printed colors is secured with a yellow rubber band. endseq', \"startseq Resting against the clean white surface, you'll find a paper adorned with diverse colors, held together by a yellow rubber band. endseq\", 'startseq The white backdrop showcases a paper with multiple colors in its print, fastened using a yellow rubber band. endseq', 'startseq Displayed on the white background is a paper embellished with various printed colors, neatly bundled with a yellow rubber band. endseq']\n",
      "['startseq A paper cup holder with prints in black on a black background with bright lighting is well-preserved. endseq', 'startseq Resting against the dark backdrop of the black background, a paper cup holder adorned with black prints is showcased in a well-preserved state, illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a paper cup holder featuring black prints that is meticulously preserved, brought to life by the brilliance of bright lighting. endseq\", 'startseq The black background serves as a dramatic canvas for a paper cup holder with black prints, which is elegantly preserved and highlighted by intense lights. endseq', 'startseq Displayed on the black background, a paper cup holder bearing black prints is showcased in excellent condition, its details illuminated by the luminosity of bright lighting. endseq']\n",
      "[\"startseq Within the scope of bright lighting, you'll encounter only a black background, and no objects are present. endseq\", \"startseq There's only a black background with no objects under bright lighting. endseq\", 'startseq Under the radiant lighting, nothing is visible except a black background. endseq', 'startseq In the well-lit space, only a black backdrop can be observed, with no objects. endseq', 'startseq Nothing is present other than a black background under the bright lighting. endseq']\n",
      "['startseq A well-preserved white plastic cup lid is present on a black background. endseq', 'startseq Resting against the dark backdrop of the black background, a white plastic cup lid that is impeccably preserved is showcased. endseq', \"startseq Positioned on the black surface, you'll find a well-maintained white plastic cup lid, presented in its excellent preservation against the dark background. endseq\", 'startseq The black background serves as a striking contrast for a white plastic cup lid in a state of perfect preservation. endseq', 'startseq Displayed on the black background is a white plastic cup lid, well-preserved and highlighted against the dark canvas. endseq']\n",
      "['startseq This setup consists of a solitary black background, lit brightly, with an utter lack of objects. endseq', 'startseq Under the strong illumination, only a black background is apparent. endseq', 'startseq In the well-lit setting, nothing exists except a black backdrop. endseq', 'startseq Only a black background can be seen under the bright lighting, with no objects. endseq', \"startseq Under the intense lighting conditions, there's solely a black background. endseq\"]\n",
      "['startseq A well-preserved transparent plastic drink container and a well-preserved transparent plastic drink container lid are combined on a black background with bright lighting. endseq', 'startseq Resting against the dark backdrop of the black background, a transparent plastic drink container and its accompanying transparent plastic drink container lid, both well-preserved, are illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a pairing of a well-maintained transparent plastic drink container and its corresponding lid, both showcased under the brilliance of bright lighting. endseq\", 'startseq The black background provides a striking contrast for a transparent plastic drink container and its lid, both in excellent preservation, brilliantly lit by intense lights. endseq', 'startseq Displayed on the black background is a combination of a transparent plastic drink container and its lid, both well-preserved and brought to life by the luminosity of bright lighting. endseq']\n",
      "['startseq The white background remains untouched by any objects. endseq', 'startseq All that is visible is the unembellished white background. endseq', 'startseq Only the white background with no decorations is in view. endseq', 'startseq The exclusive scene is the unadorned white background. endseq', \"startseq There's nothing else to look at but the empty white background. endseq\"]\n",
      "['startseq The black background appears slightly yellow due to bright lighting. endseq', 'startseq A lone white background establishes the defining aspect of the space, without objects. endseq', 'startseq The spatial parameters are exclusively determined by a white background with no objects present. endseq', 'startseq Only a solitary white background exists within the space, without objects. endseq', 'startseq The space is defined by a single white backdrop with no objects in view. endseq']\n",
      "['startseq The only sight is that of a black background under the illumination of bright lighting, with no objects in view. endseq', 'startseq The entirety of the space is encompassed by a solitary white background, with no objects in sight. endseq', 'startseq The sole defining characteristic of the space is a white background without any objects. endseq', 'startseq Within the space, there is only a solitary white background, void of objects. endseq', 'startseq The space is identified by a solitary white backdrop, absent of any objects. endseq']\n",
      "['startseq A well-preserved black plastic straw is present on a black background. endseq', 'startseq Against the backdrop of darkness, a meticulously kept black plastic straw is displayed. endseq', \"startseq Positioned on the black surface, you'll find a black plastic straw that has been well-preserved, creating a striking visual contrast. endseq\", 'startseq The black background serves as the canvas for a flawlessly maintained black plastic straw, offering a harmonious blend of elements. endseq', 'startseq Displayed on the black background is a perfectly preserved black plastic straw, adding a touch of elegance to the composition. endseq']\n",
      "['startseq A well-preserved transparent plastic container and a well-preserved transparent plastic container lid are combined in a clean state on a black background. endseq', 'startseq Resting against the sleek black background, a transparent plastic container and its corresponding lid, both well-preserved and in pristine condition, are combined harmoniously. endseq', \"startseq Positioned on the black surface, you'll find a pairing of a meticulously maintained transparent plastic container and its lid, creating a visually appealing contrast. endseq\", 'startseq The black backdrop showcases the union of a transparent plastic container and its lid, both in excellent preservation and presenting a clean appearance. endseq', 'startseq Displayed on the black background is a combination of a transparent plastic container and its well-preserved lid, both exemplifying a state of cleanliness and elegance. endseq']\n",
      "['startseq A transparent plastic item is on the white background. endseq', 'startseq Resting against the white backdrop is a clear plastic object. endseq', 'startseq Positioned on the white surface, there lies a transparent plastic item. endseq', 'startseq The white background serves as the canvas for a see-through plastic object. endseq', 'startseq On display is a translucent plastic item against the pristine white background. endseq']\n",
      "['startseq A transparent plastic container and a white paper cup holder with black letters printed on it are combined, well-preserved, on the white background. endseq', 'startseq Resting on the white background, a transparent plastic container and a white paper cup holder with black lettering are united in a well-preserved state. endseq', \"startseq Positioned against the clean white surface, you'll find a composition of a transparent plastic container and a white paper cup holder featuring black printed letters, both impeccably maintained. endseq\", 'startseq The white backdrop showcases the combination of a transparent plastic container and a white paper cup holder adorned with black letters, both preserved in excellent condition. endseq', 'startseq Displayed on the white background is a grouping that includes a transparent plastic container and a white paper cup holder bearing black letters, both well-preserved and thoughtfully combined. endseq']\n",
      "['startseq A clean and well-preserved transparent plastic container and a transparent plastic container lid are combined on a black background with bright lighting. endseq', 'startseq Resting against the dark backdrop of the black background, a transparent plastic container and its corresponding lid, both in impeccable condition, are united, illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a pairing of a meticulously maintained transparent plastic container and its lid, harmoniously combined and brought to life by the brilliance of bright lighting. endseq\", 'startseq The black background serves as a dramatic setting for a clean and well-preserved transparent plastic container and its lid, creating a striking visual contrast under the luminosity of bright lighting. endseq', 'startseq Displayed on the black background is a composition featuring a transparent plastic container and its lid, both kept in excellent preservation, beautifully illuminated by the intense lighting. endseq']\n",
      "['startseq There are no objects on a dirty white plastic background. endseq', 'startseq The dirty white plastic background is devoid of any objects. endseq', 'startseq No objects can be found on the soiled white plastic backdrop. endseq', 'startseq There are no items on the contaminated white plastic background. endseq', 'startseq The white plastic background, which is dirty, is empty of objects. endseq']\n",
      "['startseq The absence of objects results in a white background. endseq', 'startseq In view is solely the modest white backdrop. endseq', 'startseq The only thing in sight is the white background without embellishments. endseq', 'startseq A tainted white plastic backdrop is the exclusive sight. endseq', 'startseq There is but a polluted white plastic background to be found. endseq']\n",
      "['startseq A clean and well-preserved transparent plastic drink container is present on a black background with bright lighting. endseq', 'startseq Resting against the dark expanse of the black background, a transparent plastic drink container in impeccable condition is illuminated by intense lighting. endseq', \"startseq Positioned on the black backdrop, you'll find a transparent plastic drink container that is both clean and well-preserved, enhanced by the brilliance of bright lighting. endseq\", 'startseq The black background provides a striking contrast for a transparent plastic drink container that is pristine and flawlessly maintained, brilliantly lit by intense lights. endseq', 'startseq Displayed on the black background, a transparent plastic drink container showcases its immaculate state under the luminous impact of bright lighting. endseq']\n",
      "['startseq Well-preserved transparent plastic containers and transparent plastic container lids are combined on a black background with bright lighting. endseq', 'startseq Resting against the dark backdrop of the black background, a combination of well-preserved transparent plastic containers and their corresponding lids is illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a grouping of meticulously maintained transparent plastic containers and their lids, all harmoniously combined and brought to life by the brilliance of bright lighting. endseq\", 'startseq The black background serves as a striking canvas for the presence of well-preserved transparent plastic containers and their lids, all showcased under the luminosity of bright lighting. endseq', 'startseq Displayed on the black background is a composition featuring transparent plastic containers and their lids, all in excellent condition, beautifully illuminated by the intense lighting. endseq']\n",
      "['startseq A clean and well-preserved transparent plastic drink container lid is present on a black background with bright lighting. endseq', 'startseq Positioned against the dark canvas of the black background, a transparent plastic drink container lid, impeccably clean and well-maintained, is illuminated by intense lighting. endseq', 'startseq Resting on the black backdrop, a transparent plastic drink container lid in excellent preservation stands out under the brilliance of bright lighting. endseq', 'startseq The black background provides a striking contrast for a transparent plastic drink container lid that is both clean and well-preserved, brilliantly lit by intense lights. endseq', 'startseq Displayed on the black background, a transparent plastic drink container lid showcases its immaculate state, accentuated by the luminosity of bright lighting. endseq']\n",
      "['startseq A slightly contaminated transparent PET bottle container and a well-preserved white PET bottle cap are combined on the white background. endseq', 'startseq Resting on the white background, a transparent PET bottle container with minor contamination is paired with a white PET bottle cap that remains well-preserved. endseq', \"startseq Positioned against the clean white surface, you'll find a composition featuring a transparent PET bottle container showing slight contamination, combined with a white PET bottle cap in excellent preservation. endseq\", 'startseq The white backdrop showcases a combination of elements: a slightly contaminated transparent PET bottle container and a white PET bottle cap that is well-maintained. endseq', 'startseq Displayed on the white background is a grouping that includes a transparent PET bottle container with minor contamination and a white PET bottle cap, both combined harmoniously. endseq']\n",
      "['startseq An orange paper cup holder with mild damage, two well-preserved plastic beverage containers, and a well-preserved orange plastic straw are present. endseq', 'startseq Within the scene, an orange paper cup holder exhibiting minor damage is accompanied by two impeccably maintained plastic beverage containers and a well-preserved orange plastic straw. endseq', 'startseq The arrangement includes an orange paper cup holder with slight wear, alongside two pristine plastic beverage containers and a carefully preserved orange plastic straw. endseq', 'startseq Among the elements present are an orange paper cup holder showing mild signs of damage, two flawlessly maintained plastic beverage containers, and a perfectly preserved orange plastic straw. endseq', 'startseq On display are an orange paper cup holder with minor wear and tear, two meticulously kept plastic beverage containers, and a well-maintained orange plastic straw. endseq']\n",
      "['startseq A transparent plastic drink lid with low contamination and a well-preserved white paper straw are combined together on a dark area of the white background. endseq', 'startseq In a shaded section of the white background, a transparent plastic drink lid with minimal contamination is paired with a meticulously maintained white paper straw. endseq', 'startseq Against a darker section of the white background, a clear plastic drink lid showing slight contamination is united with a carefully preserved white paper straw. endseq', 'startseq A well-preserved white paper straw and a transparent plastic drink lid, displaying low levels of contamination, are brought together on a darker portion of the white background. endseq', \"startseq Positioned on a darker area of the white background, you'll find a transparent plastic drink lid with minor contamination, combined harmoniously with a pristine white paper straw. endseq\"]\n",
      "['startseq The bright light makes the white plastic background hard to see. endseq', 'startseq There exists solely a polluted white plastic backdrop. endseq', \"startseq There's just a tainted white plastic background. endseq\", 'startseq The only element in view is a polluted white plastic backdrop. endseq', 'startseq Only a contaminated white plastic background can be observed. endseq']\n",
      "['startseq The backdrop is purely white, without any objects. endseq', 'startseq A tainted white plastic backdrop is the exclusive presence. endseq', 'startseq There is but a polluted white plastic background. endseq', 'startseq Solely a contaminated white plastic surface is in sight. endseq', 'startseq A polluted white plastic background is the singular entity. endseq']\n",
      "['startseq A pink plastic spoon and a paper container with various colors printed on it and high contamination are well-preserved on the white background. endseq', 'startseq Positioned on the white background, a well-preserved pink plastic spoon accompanies a paper container adorned with multiple colors in its print, yet displaying significant contamination. endseq', \"startseq Resting against the clean white surface, you'll find a pink plastic spoon that has been maintained in good condition, alongside a paper container featuring a variety of printed colors but showing noticeable contamination. endseq\", 'startseq The white backdrop showcases a pink plastic spoon in excellent preservation, along with a paper container showcasing various colors in its print, though marred by substantial contamination. endseq', 'startseq Displayed on the white background is a pink plastic spoon that remains well-kept, paired with a paper container featuring diverse printed colors, despite its high level of contamination. endseq']\n",
      "['startseq No items are present, just a plain white background. endseq', 'startseq There exists solely a polluted white plastic backdrop. endseq', \"startseq There's just a tainted white plastic background. endseq\", 'startseq The only element in view is a polluted white plastic backdrop. endseq', 'startseq Only a contaminated white plastic background can be observed. endseq']\n",
      "['startseq A green paper cup holder, a heavily contaminated transparent plastic container, a transparent plastic container lid, and a transparent plastic straw are combined on the white background. endseq', 'startseq Resting on the white background, a green paper cup holder is combined with a transparent plastic container showing heavy contamination, along with a transparent plastic container lid and a transparent plastic straw. endseq', \"startseq Positioned against the clean white surface, you'll find a composition of a green paper cup holder, a transparent plastic container heavily affected by contamination, a transparent plastic container lid, and a transparent plastic straw. endseq\", 'startseq The white backdrop presents a combination of elements: a green paper cup holder, a transparent plastic container with noticeable contamination, a transparent plastic container lid, and a transparent plastic straw. endseq', 'startseq Displayed on the white background is a grouping featuring a green paper cup holder, a transparent plastic container marked by significant contamination, a transparent plastic container lid, and a transparent plastic straw. endseq']\n",
      "['startseq A black plastic straw with low contamination and well-preserved shape is present on a black background with bright lighting. endseq', 'startseq Resting against the dark expanse of the black background, a black plastic straw, displaying minimal contamination and retaining its original shape, is illuminated by intense lighting. endseq', \"startseq Positioned on the black backdrop, you'll find a black plastic straw that is well-preserved in shape and exhibits only a low level of contamination, enhanced by the brilliance of bright lighting. endseq\", 'startseq The black background provides a stark contrast for a black plastic straw with minimal contamination and excellent preservation of its shape, brilliantly lit by intense lights. endseq', 'startseq Displayed on the black background, a black plastic straw showcases its well-preserved form and subtle contamination, accentuated by the luminosity of bright lighting. endseq']\n",
      "['startseq A paper cup holder with black letters printed on it and a well-preserved black plastic straw are well-preserved on a black plastic background with bright lighting. endseq', 'startseq Resting against the dark expanse of the black plastic background, a paper cup holder featuring black printed letters and a carefully maintained black plastic straw are showcased under the brilliance of bright lighting. endseq', \"startseq Positioned on the black plastic surface, you'll find a composition of a well-preserved paper cup holder with black letters and a black plastic straw, both illuminated by intense lighting against the backdrop of darkness. endseq\", 'startseq The black plastic background creates a striking contrast for a paper cup holder with black letters and a well-preserved black plastic straw, both elegantly preserved and illuminated by bright lights. endseq', 'startseq Displayed on the black plastic background is a pairing of a paper cup holder adorned with black letters and a black plastic straw, both well-maintained and brought to life by the luminosity of bright lighting. endseq']\n",
      "['startseq Well-preserved transparent plastic containers, a white paper cup holder, a transparent plastic container lid, and an orange plastic straw are present on a black background with bright lighting. endseq', \"startseq Resting against the dark backdrop of the black background, you'll find well-preserved transparent plastic containers, a white paper cup holder, a transparent plastic container lid, and an orange plastic straw, all illuminated by intense lighting. endseq\", 'startseq Positioned on the black surface, a combination of well-maintained transparent plastic containers, a white paper cup holder, a transparent plastic container lid, and an orange plastic straw are brought to life under the brilliance of bright lighting. endseq', 'startseq The black background provides a dramatic canvas for the presence of well-preserved transparent plastic containers, a white paper cup holder, a transparent plastic container lid, and an orange plastic straw, all enhanced by the luminosity of bright lighting. endseq', 'startseq Displayed on the black background is a grouping of transparent plastic containers, a white paper cup holder, a transparent plastic container lid, and an orange plastic straw, all showcased in their well-preserved state, accentuated by the intense illumination of bright lighting. endseq']\n",
      "['startseq Only a black background under bright lighting is present without any objects. endseq', \"startseq There's merely a black background. endseq\", 'startseq The sole thing present is a black background. endseq', 'startseq There is but a black background. endseq', 'startseq A black background is the only sight. endseq']\n",
      "['startseq A well-preserved white vinyl pack with red onions and letters printed in red is present on a black background with bright lighting. endseq', 'startseq Resting against the dark canvas of the black background, a white vinyl pack showcasing red onions and printed letters in red is impeccably preserved, illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a well-maintained white vinyl pack featuring red onions and red printed letters, all brought to life under the brilliance of bright lighting. endseq\", 'startseq The black background provides a striking contrast for a white vinyl pack displaying red onions and red printed letters, which are both elegantly preserved and illuminated by intense lights. endseq', 'startseq Displayed on the black background is a composition featuring a well-preserved white vinyl pack adorned with red onions and red printed letters, all captivatingly accentuated by the luminosity of bright lighting. endseq']\n",
      "['startseq Only a white background is present in a dirty state. endseq', 'startseq The exclusive panorama is the simple white background. endseq', \"startseq There's nothing else to see but the empty white background. endseq\", 'startseq In view is solely the stark white backdrop. endseq', 'startseq The only thing in sight is the white background without enhancements. endseq']\n",
      "['startseq A well-preserved transparent plastic straw with low contamination is present on a black background. endseq', 'startseq Resting against the dark canvas of the black background, a transparent plastic straw in excellent condition, displaying minimal contamination, is showcased. endseq', \"startseq Positioned on the black surface, you'll find a meticulously maintained transparent plastic straw with slight contamination, brought to life against the dark background. endseq\", 'startseq The black background provides a striking contrast for a transparent plastic straw that is well-preserved and only lightly contaminated. endseq', 'startseq Displayed on the black background is a transparent plastic straw that stands out in its well-preserved state, its minimal contamination highlighted against the darkness. endseq']\n",
      "['startseq A green paper cup holder, a heavily contaminated transparent plastic container, a transparent plastic drink container lid, and a transparent plastic straw are combined on the white background. endseq', 'startseq Resting on the white background, a green paper cup holder is combined with a transparent plastic container heavily affected by contamination, a transparent plastic drink container lid, and a transparent plastic straw. endseq', \"startseq Positioned against the clean white surface, you'll see a fusion of a green paper cup holder, a transparent plastic container displaying significant contamination, a transparent plastic drink container lid, and a transparent plastic straw. endseq\", 'startseq The white backdrop showcases a combination of elements: a green paper cup holder, a heavily contaminated transparent plastic container, a transparent plastic drink container lid, and a transparent plastic straw. endseq', 'startseq Displayed on the white background is a composition featuring a green paper cup holder, a transparent plastic container marked by extensive contamination, a transparent plastic drink container lid, and a transparent plastic straw. endseq']\n",
      "['startseq A gray paper with well-preserved shape and low contamination is on the white background. endseq', \"startseq Resting against the clean white surface, you'll find a gray paper that retains its well-preserved shape and exhibits only a low level of contamination. endseq\", 'startseq Positioned on the white background, there lies a gray paper with a shape that has been maintained and displaying minimal contamination. endseq', 'startseq The white backdrop showcases a gray paper with its shape well-preserved and its surface showing only a slight degree of contamination. endseq', 'startseq Displayed on the white background is a gray paper that remains in good shape, accompanied by a low level of contamination. endseq']\n",
      "['startseq There are no objects on a dirty white plastic background. endseq', 'startseq A contaminated white plastic background is the singular sight. endseq', \"startseq There's only a tainted white plastic backdrop to be seen. endseq\", 'startseq The sole thing present is a polluted white plastic backdrop. endseq', 'startseq There exists solely a contaminated white plastic surface. endseq']\n",
      "['startseq Only a black background is present. endseq', 'startseq The sole defining characteristic of the space is a white background without any objects. endseq', 'startseq Within the space, there is only a solitary white background, void of objects. endseq', 'startseq The space is identified by a solitary white backdrop, absent of any objects. endseq', 'startseq A lone white background establishes the defining aspect of the space, without objects. endseq']\n",
      "['startseq There is only a white background with no objects. endseq', \"startseq There's just a polluted white plastic background in view. endseq\", 'startseq Only a contaminated white plastic backdrop is observable. endseq', 'startseq A tainted white plastic backdrop is the exclusive entity. endseq', 'startseq There is but a polluted white plastic surface. endseq']\n",
      "['startseq A folded paper cup holder with prints in various colors is well-preserved on a black background with bright lighting. endseq', 'startseq Resting against the dark canvas of the black background, a folded paper cup holder adorned with prints in a spectrum of colors is impeccably preserved, illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a well-maintained folded paper cup holder featuring prints in various colors, brought to life under the brilliance of bright lighting. endseq\", 'startseq The black background serves as a striking contrast for a folded paper cup holder showcasing prints in diverse colors, all elegantly preserved and illuminated by intense lights. endseq', 'startseq Displayed on the black background, a folded paper cup holder with prints in various colors stands out, its well-preserved state highlighted by the luminosity of bright lighting. endseq']\n",
      "['startseq A well-preserved black plastic straw is present on a black background. endseq', 'startseq Resting against the dark expanse of the black background, a meticulously maintained black plastic straw is displayed. endseq', \"startseq Positioned on the black surface, you'll find a black plastic straw that remains in excellent preservation, set against the backdrop of darkness. endseq\", 'startseq The black background serves as the canvas for a well-preserved black plastic straw, creating a captivating contrast. endseq', 'startseq Displayed on the black background is a black plastic straw that is beautifully preserved, creating an elegant visual composition. endseq']\n",
      "['startseq A heavily contaminated and damaged object is present on the white background. endseq', 'startseq Positioned on the white background is an object displaying severe contamination and damage. endseq', \"startseq Resting against the clean white surface, you'll find an item heavily affected by both contamination and damage. endseq\", 'startseq The white backdrop showcases an object that is deeply marred by contamination and significant damage. endseq', 'startseq Displayed on the white background is an object that bears the brunt of heavy contamination and shows substantial damage. endseq']\n",
      "['startseq There are no objects to be found on the white background. endseq', 'startseq All one can perceive is the bare white backdrop. endseq', 'startseq Only the white background devoid of content is in sight. endseq', 'startseq The exclusive view is the vacant white background. endseq', \"startseq There's nothing else to see but the empty white background. endseq\"]\n",
      "['startseq A black plastic straw is well-preserved on the white background. endseq', 'startseq On the white background, a pristine black plastic straw is impeccably maintained. endseq', \"startseq Resting against the clean white surface, you'll find a well-preserved black plastic straw. endseq\", 'startseq The white backdrop highlights a perfectly kept black plastic straw. endseq', 'startseq Displayed on the white background is a black plastic straw in excellent condition. endseq']\n",
      "['startseq A well-preserved white paper cup holder with black letters printed on it is present on a black background with bright lighting. endseq', 'startseq Resting against the dark canvas of the black background, a white paper cup holder with black printed letters is showcased under the brilliance of bright lighting, revealing its excellent preservation. endseq', \"startseq Positioned on the black surface, you'll find a well-maintained white paper cup holder featuring black lettering, illuminated by intense lighting against the backdrop of darkness. endseq\", 'startseq The black background serves as the perfect contrast for a well-preserved white paper cup holder with black letters, brought to life by the luminosity of bright lighting. endseq', 'startseq Displayed on the black background, a white paper cup holder with black printed letters stands out elegantly, accentuated by the intense illumination of bright lighting. endseq']\n",
      "['startseq An orange paper cup holder with mild damage and a well-preserved orange plastic straw are layered on the white background. endseq', 'startseq On the white background, an orange paper cup holder showing slight wear and tear is layered together with a carefully maintained orange plastic straw. endseq', 'startseq Resting on the white surface, a slightly damaged orange paper cup holder is layered with an orange plastic straw that remains in excellent condition. endseq', 'startseq An orange paper cup holder displaying minor damage is layered upon a white background along with a pristine orange plastic straw. endseq', 'startseq The white background serves as the backdrop for a layered arrangement of a mildly worn orange paper cup holder and a well-kept orange plastic straw. endseq']\n",
      "['startseq A well-preserved transparent plastic container and a transparent plastic container lid are combined on a black background under bright lighting. endseq', 'startseq Resting against the dark canvas of the black background, a transparent plastic container and its corresponding lid, both immaculately preserved, are united and illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a pairing of a well-maintained transparent plastic container and its lid, harmoniously combined and brought to life by the brilliance of bright lighting. endseq\", 'startseq The black background serves as a dramatic canvas for a clean and well-preserved transparent plastic container and its lid, accentuated by the luminosity of bright lighting. endseq', 'startseq Displayed on the black background is a composition featuring a transparent plastic container and its lid, both impeccably maintained, elegantly illuminated by the intense lighting. endseq']\n",
      "['startseq A white object with a damaged shape is present on the black background. endseq', 'startseq Resting against the dark canvas of the black background, a white object displaying a distorted shape is showcased. endseq', \"startseq Positioned on the black surface, you'll find a white object with a shape that has been compromised, standing out against the dark background. endseq\", 'startseq The black background creates a dramatic contrast for a white object that bears the marks of a damaged shape. endseq', 'startseq Displayed on the black background is a white object with an altered shape, accentuated by the darkness that surrounds it. endseq']\n",
      "['startseq The bright light makes the white plastic background hard to see. endseq', 'startseq There is only a white plastic backdrop contaminated by impurity. endseq', 'startseq Only a polluted white plastic surface can be observed. endseq', 'startseq A contaminated white plastic background is the sole view. endseq', \"startseq There's only a tainted white plastic backdrop to be observed. endseq\"]\n",
      "['startseq A crumpled white paper garbage is on the left side of the white background. endseq', 'startseq Positioned on the left side of the white background is a crumpled white paper, discarded as garbage. endseq', \"startseq Resting against the white backdrop, you'll see a crumpled white paper that has been discarded as waste, situated on the left side. endseq\", 'startseq The left side of the white background features a crumpled white paper that has been disposed of as trash. endseq', 'startseq Displayed on the left portion of the white background is a discarded crumpled white paper, indicative of waste. endseq']\n",
      "['startseq A well-preserved black plastic straw with low contamination and well-preserved shape is present on a black background with bright lighting. endseq', 'startseq Resting against the dark canvas of the black background, a black plastic straw that is well-preserved in shape and shows minimal contamination is illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a well-maintained black plastic straw exhibiting excellent shape and displaying only slight contamination, enhanced by the brilliance of bright lighting. endseq\", 'startseq The black background provides a stark contrast for a black plastic straw with preserved shape and minimal contamination, brilliantly lit by intense lights. endseq', 'startseq Displayed on the black background is a black plastic straw that retains its well-preserved form and bears only slight contamination, accentuated by the luminosity of bright lighting. endseq']\n",
      "['startseq A black plastic straw is on a black plastic background with bright lighting. endseq', 'startseq Positioned against the sleek black plastic background, a black plastic straw stands illuminated by bright lighting. endseq', 'startseq Resting on the black plastic surface, a black plastic straw is accentuated by vibrant lighting. endseq', 'startseq The black plastic backdrop provides a striking contrast for a black plastic straw, brilliantly lit by intense lights. endseq', 'startseq Displayed on the black plastic background, a black plastic straw is highlighted by the luminosity of bright lighting, creating a bold visual impact. endseq']\n",
      "['startseq All that can be seen is the empty white background. endseq', 'startseq Only the vacant white backdrop is visible. endseq', 'startseq The sole sight is the blank white background. endseq', \"startseq What's observable is solely the empty white background. endseq\", 'startseq There is nothing in view except the white background. endseq']\n",
      "['startseq A transparent plastic drink lid and container are well-preserved on the white background. endseq', 'startseq The white background hosts a transparent plastic lid and container, both impeccably maintained. endseq', 'startseq On the clean white surface, a transparent plastic drink lid and container are presented in their pristine condition. endseq', 'startseq A transparent plastic lid and container for beverages are gracefully displayed against a backdrop of white, showcasing their excellent preservation. endseq', 'startseq Resting on the white background, a transparent plastic drink lid and container remain in superbly kept condition. endseq']\n",
      "['startseq A plastic beverage container with prints in yellow and brown is placed diagonally on a dirty white background. endseq', 'startseq Positioned diagonally on the grime-speckled white background is a plastic beverage container adorned with prints in shades of yellow and brown. endseq', \"startseq Resting against the slightly soiled white surface, you'll find a plastic beverage container featuring prints in both yellow and brown, placed diagonally. endseq\", 'startseq The white backdrop, marred by dirt, holds a plastic beverage container with prints in yellow and brown, positioned diagonally for visual impact. endseq', 'startseq Displayed on the diagonally placed, slightly dirty white background is a plastic beverage container decorated with yellow and brown prints. endseq']\n",
      "['startseq A crumpled transparent vinyl is on the white background. endseq', 'startseq Positioned on the white background is a transparent vinyl that has been crumpled. endseq', \"startseq Resting against the clean white surface, you'll find a crumpled see-through vinyl. endseq\", 'startseq The white backdrop showcases a transparent vinyl that is crumpled in its appearance. endseq', 'startseq Displayed on the white background is a crumpled vinyl that retains its transparency. endseq']\n",
      "['startseq There is only a white background with no objects. endseq', 'startseq In the presence of dim lighting, a polluted white plastic surface is evident. endseq', 'startseq A dimly lit area reveals a contaminated white plastic backdrop. endseq', 'startseq Under low illumination, there exists a tainted white plastic background. endseq', 'startseq A polluted white plastic background can be seen in the dim light. endseq']\n",
      "['startseq A red-lettered paper beverage container with damaged shape is on the white background. endseq', 'startseq Positioned against the white backdrop is a paper beverage container with red lettering, its shape showing signs of damage. endseq', \"startseq Resting on the clean white surface, you'll see a paper beverage container featuring red lettering, though its shape has been compromised. endseq\", 'startseq The white background hosts a red-lettered paper beverage container that has suffered damage to its original shape. endseq', 'startseq Displayed on the white background is a paper beverage container with red lettering, its form visibly altered due to damage. endseq']\n",
      "['startseq A well-preserved transparent plastic container, a transparent plastic container lid, and an orange plastic straw are combined on a black background. endseq', 'startseq Resting against the dark backdrop of the black background, a combination of well-preserved transparent plastic container, its lid, and an orange plastic straw creates a visually appealing ensemble. endseq', \"startseq Positioned on the black surface, you'll find a grouping of a meticulously maintained transparent plastic container, its lid, and an orange plastic straw, all showcased against the dark background. endseq\", 'startseq The black background provides a stark contrast for the presence of a well-preserved transparent plastic container, its lid, and an orange plastic straw, all harmoniously combined. endseq', 'startseq Displayed on the black background is a composition featuring a well-preserved transparent plastic container, its lid, and an orange plastic straw, creating an engaging visual display against the dark backdrop. endseq']\n",
      "['startseq The white background is not clearly visible due to the bright light. endseq', 'startseq Solely a contaminated white plastic background is apparent. endseq', 'startseq A polluted white plastic backdrop is the sole object. endseq', \"startseq There's merely a tainted white plastic surface to be observed. endseq\", 'startseq The exclusive element is a polluted white plastic backdrop. endseq']\n",
      "['startseq Nothing populates the view except for an empty white background. endseq', 'startseq Dim lighting exposes the presence of a polluted white plastic background. endseq', 'startseq In the low light setting, there is a tainted white plastic surface. endseq', 'startseq A contaminated white plastic backdrop is visible in the dim light. endseq', 'startseq Under subdued lighting, a white plastic background is tainted. endseq']\n",
      "['startseq Only the plain white background is present, devoid of any objects. endseq', 'startseq A contaminated white plastic backdrop is the only thing there. endseq', \"startseq There's only a polluted white plastic background. endseq\", 'startseq Only a tainted white plastic surface can be seen. endseq', 'startseq The sole presence is a contaminated white plastic backdrop. endseq']\n",
      "['startseq The backdrop consists solely of an empty white space. endseq', 'startseq In view is solely the blank white backdrop. endseq', 'startseq The only thing in sight is the unoccupied white background. endseq', 'startseq All that meets the eye is the featureless white background. endseq', 'startseq Only the plain white background is visible. endseq']\n",
      "['startseq A well-preserved brown paper cup holder is present on a black background with bright lighting. endseq', 'startseq Resting against the dark canvas of the black background, a brown paper cup holder in excellent preservation is illuminated by intense lighting, showcasing its details. endseq', \"startseq Positioned on the black surface, you'll find a well-maintained brown paper cup holder that is elegantly preserved, brought to life under the brilliance of bright lighting. endseq\", 'startseq The black background provides a striking contrast for a brown paper cup holder in pristine condition, accentuated by the luminosity of bright lighting. endseq', 'startseq Displayed on the black background is a brown paper cup holder that stands out with its well-preserved state, its features emphasized by the intense illumination of bright lighting. endseq']\n",
      "['startseq The scene is devoid of any objects, featuring solely a white background. endseq', 'startseq In view is solely the unornamented white backdrop. endseq', 'startseq The only thing in sight is the white background without embellishments. endseq', 'startseq All that can be witnessed is the vacant white background. endseq', 'startseq Only the clean white backdrop is visible. endseq']\n",
      "['startseq A brown paper bag with well-preserved shape is present on a black background under bright lighting. endseq', 'startseq Resting against the dark expanse of the black background, a brown paper bag with an impeccably maintained shape is illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a well-preserved brown paper bag that retains its original form, brought to life by the brilliance of bright lighting. endseq\", 'startseq The black background provides a striking contrast for a brown paper bag with its shape well-preserved, accentuated by the luminosity of bright lighting. endseq', 'startseq Displayed on the black background is a brown paper bag showcasing its well-maintained shape, its details brought to the forefront by the intense illumination of bright lighting. endseq']\n",
      "['startseq There are no objects on a dirty white plastic background. endseq', \"startseq There's just a contaminated white plastic setting. endseq\", 'startseq The sole element is a polluted white plastic background. endseq', 'startseq Only a tainted white plastic background is present. endseq', 'startseq A contaminated white plastic backdrop is the singular presence. endseq']\n",
      "['startseq Well-preserved transparent plastic container lids, a black plastic straw, and a paper cup holder with black background and white letter prints are present on a black background with bright lighting. endseq', 'startseq Resting against the dark expanse of the black background, a combination of well-preserved transparent plastic container lids, a black plastic straw, and a paper cup holder with black background and white letter prints is illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a grouping of meticulously maintained transparent plastic container lids, a black plastic straw, and a paper cup holder adorned with white letter prints on a black background. All elements are brought to life by the brilliance of bright lighting. endseq\", 'startseq The black background provides a dramatic setting for the presence of well-preserved transparent plastic container lids, a black plastic straw, and a paper cup holder featuring white letter prints on black. All elements are elegantly showcased under the luminosity of bright lighting. endseq', 'startseq Displayed on the black background is a composition featuring transparent plastic container lids, a black plastic straw, and a paper cup holder with white letter prints on black. All items are in excellent condition and beautifully accentuated by the intense lighting. endseq']\n",
      "['startseq There are no objects on the black plastic background. endseq', 'startseq The entirety of the space is occupied by a solitary white background, free from objects. endseq', 'startseq The sole defining aspect of the space is a white background without any objects present. endseq', 'startseq Within the space, there is only a solitary white background, void of objects. endseq', 'startseq The space is identified by a solitary white backdrop, with no objects in view. endseq']\n",
      "['startseq A transparent PET bottle and a blue PET bottle cap are combined together and shaken on the white background. endseq', 'startseq Resting on the white background, a transparent PET bottle is paired with a blue PET bottle cap, creating a duo that is shaken together. endseq', \"startseq Positioned against the clean white surface, you'll find a transparent PET bottle combined with a blue PET bottle cap, their contents mixed by shaking. endseq\", 'startseq The white backdrop showcases the combination of a clear PET bottle and a blue PET bottle cap, brought together and agitated by shaking. endseq', 'startseq Displayed on the white background is a transparent PET bottle and a blue PET bottle cap, joined and set in motion through shaking. endseq']\n",
      "['startseq Nothing populates the scene except for a black background illuminated by bright lighting. endseq', 'startseq The space is outlined solely by a white background, absent of objects. endseq', 'startseq The entire space is encompassed by a solitary white background, with no objects in sight. endseq', 'startseq The sole defining feature of the space is a white background without objects. endseq', 'startseq There is only a single white background within the space, void of objects. endseq']\n",
      "['startseq Solely a black background is observable in the midst of bright lighting, with no objects present. endseq', 'startseq The space is marked by a solitary white backdrop, devoid of any objects. endseq', 'startseq A lone white background serves as the defining element in the space, without objects. endseq', 'startseq The spatial parameters are determined solely by a white background with no objects present. endseq', 'startseq Only a solitary white background occupies the entirety of the space, free from objects. endseq']\n",
      "['startseq A white paper is folded on a black background with bright lighting. endseq', 'startseq Resting against the dark canvas of the black background, a white paper is neatly folded and illuminated by intense lighting. endseq', \"startseq Positioned on the black backdrop, you'll find a white paper that has been folded, its details highlighted by bright lighting. endseq\", 'startseq The black background serves as a dramatic contrast to a folded white paper, which is brought to life by the brilliance of bright lighting. endseq', 'startseq Displayed on the black background, a white paper is elegantly folded and accentuated by the luminosity of bright lighting. endseq']\n",
      "['startseq There are no objects; the only thing visible is a black background illuminated by bright lighting. endseq', 'startseq Only a black background is visible under the bright lights, with no objects in sight. endseq', \"startseq In the presence of bright lighting, there's nothing else but a black backdrop. endseq\", \"startseq There's only a black background in the absence of objects under bright lighting. endseq\", 'startseq Under the radiant lighting, nothing is present except a black background. endseq']\n",
      "['startseq Cleaning a dirty white plastic background by hand. endseq', 'startseq Hand-cleaning a soiled white plastic backdrop. endseq', 'startseq Manual cleaning of a grimy white plastic background. endseq', 'startseq Cleaning a stained white plastic background manually. endseq', 'startseq Using hands to clean a dirty white plastic backdrop. endseq']\n",
      "['startseq Bright lighting reveals nothing but a black background, with no objects in the frame. endseq', \"startseq Under intense illumination, there's only a black background, and no objects. endseq\", 'startseq Only a black background is evident under the bright lights, with no objects present. endseq', \"startseq In the presence of bright lighting, there's just a black backdrop. endseq\", \"startseq There's nothing but a black background, devoid of objects, under bright lighting. endseq\"]\n",
      "['startseq An orange plastic straw is present on a black background with bright lighting. endseq', 'startseq Resting against the dark expanse of the black background, an orange plastic straw stands out vividly, illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find an orange plastic straw that catches the eye under the brilliance of bright lighting. endseq\", 'startseq The black background provides a striking contrast for an orange plastic straw, showcased in vibrant detail against the darkness and illuminated by intense lights. endseq', 'startseq Displayed on the black background is an orange plastic straw that stands out boldly, brought to life by the luminosity of bright lighting. endseq']\n",
      "['startseq The bright light makes the white plastic background hard to see. endseq', 'startseq The sole presence is a polluted white plastic surface. endseq', 'startseq There exists solely a contaminated white plastic backdrop. endseq', \"startseq There's just a polluted white plastic background to be seen. endseq\", 'startseq Only a contaminated white plastic backdrop is in sight. endseq']\n",
      "['startseq The intense light makes it difficult to clearly perceive the white background. endseq', \"startseq There's just a polluted white plastic background in view. endseq\", 'startseq Only a contaminated white plastic backdrop is observable. endseq', 'startseq A tainted white plastic backdrop is the exclusive entity. endseq', 'startseq There is but a polluted white plastic surface. endseq']\n",
      "['startseq The white background is situated within a dimly lit space. endseq', 'startseq Solely a contaminated white plastic background is apparent. endseq', 'startseq A polluted white plastic backdrop is the sole object. endseq', \"startseq There's merely a tainted white plastic surface to be observed. endseq\", 'startseq The exclusive element is a polluted white plastic backdrop. endseq']\n",
      "['startseq Only a black background is present. endseq', 'startseq The space is defined by a single white backdrop with no objects in view. endseq', 'startseq The boundaries of the space are clearly defined by a solitary white background without objects. endseq', 'startseq A solitary white backdrop serves as the sole defining element within the space, devoid of objects. endseq', 'startseq The space is outlined solely by a white background, with no objects in sight. endseq']\n",
      "['startseq A white paper is present on a black background with bright lighting. endseq', 'startseq Positioned on the dark expanse of the black background, a white paper stands illuminated by bright lighting. endseq', 'startseq Resting against the black backdrop, a white paper is illuminated with vibrant lighting. endseq', 'startseq The black background provides a striking contrast for a white paper, brilliantly lit by bright lights. endseq', 'startseq Displayed on the black background, a white paper is bathed in intense illumination, creating a stark visual contrast. endseq']\n",
      "['startseq A slightly damp black background is present. endseq', 'startseq There is nothing but a black background. endseq', 'startseq The sole presence is a black background. endseq', 'startseq Only a black backdrop exists. endseq', 'startseq Nothing else is here except for a black background. endseq']\n",
      "['startseq Under the influence of bright lighting, solely a black background exists, lacking any objects. endseq', 'startseq A lone white backdrop shapes the space, devoid of objects. endseq', 'startseq The area is delineated by a single white backdrop with no objects. endseq', 'startseq Only a single white background occupies the space, free of objects. endseq', 'startseq The spatial boundaries are marked by a solitary white background without objects. endseq']\n",
      "['startseq A green paper cup holder is slightly shaken on a black background under bright lighting. endseq', 'startseq Resting against the dark canvas of the black background, a green paper cup holder is gently agitated, its movement captured under the brilliance of bright lighting. endseq', \"startseq Positioned on the black surface, you'll find a slightly shaken green paper cup holder, its subtle motion enhanced by the intensity of bright lighting. endseq\", 'startseq The black background provides a dramatic setting for a green paper cup holder that is delicately shaken, its motion illuminated by the luminosity of bright lighting. endseq', 'startseq Displayed on the black background, a green paper cup holder is elegantly depicted in a state of gentle agitation, brought to life by the intense illumination of bright lighting. endseq']\n",
      "['startseq There is only a white background with no objects. endseq', 'startseq A contaminated white plastic backdrop is the only thing there. endseq', \"startseq There's only a polluted white plastic background. endseq\", 'startseq Only a tainted white plastic surface can be seen. endseq', 'startseq The sole presence is a contaminated white plastic backdrop. endseq']\n",
      "['startseq A clean and well-preserved transparent plastic container and a transparent plastic container lid are combined, slightly shaken, on a black background with bright lighting. endseq', 'startseq Resting against the dark canvas of the black background, a transparent plastic container and its accompanying lid, both impeccably clean and well-preserved, are combined and gently agitated, illuminated by intense lighting. endseq', \"startseq Positioned on the black surface, you'll find a pairing of a transparent plastic container and its lid, both in pristine condition, combined and given a subtle shake, all under the brilliance of bright lighting. endseq\", 'startseq The black background provides a striking contrast for a clean and well-preserved transparent plastic container and its lid, which are united and slightly shaken, enhanced by the luminosity of bright lighting. endseq', 'startseq Displayed on the black background is a composition of a transparent plastic container and its lid, both maintained in excellent condition, gently shaken to life under the intense illumination of bright lighting. endseq']\n",
      "['startseq The white background is the sole element within a darkened region. endseq', 'startseq In the subdued illumination, there is a tainted white plastic surface. endseq', 'startseq A contaminated white plastic backdrop is visible under dim lighting. endseq', 'startseq Under dim lighting, a white plastic background is tainted. endseq', 'startseq In the dimly lit environment, there exists a polluted white plastic backdrop. endseq']\n",
      "['startseq A beverage can with a peach illustration and black letters printed on a pink background is well-preserved on the white background. endseq', 'startseq On the white background, a beverage can adorned with a peach illustration and black lettering stands in excellent condition. endseq', 'startseq Resting against the white backdrop, a well-maintained beverage can showcases a peach illustration and black text on a pink background. endseq', 'startseq A beverage can featuring a peach illustration and black letters on a pink background is preserved beautifully on the white surface. endseq', 'startseq The white background accentuates a well-preserved beverage can, embellished with a peach illustration and black lettering, set against a pink background. endseq']\n",
      "['startseq The composition consists exclusively of a white background, void of any objects. endseq', 'startseq The environment is characterized by a lone white backdrop, void of objects. endseq', \"startseq There's nothing within the space except for a solitary white background. endseq\", 'startseq The confines of the space are established by a lone white background with no objects. endseq', 'startseq A solitary white backdrop defines the entirety of the space, without objects. endseq']\n",
      "['startseq A white vinyl with low contamination and mild damage is present on the white background. endseq', \"startseq Resting on the white background, you'll find a white vinyl that displays a slight level of contamination and bears mild signs of damage. endseq\", 'startseq Positioned against the clean white surface, there is a white vinyl with minor damage and a low level of contamination. endseq', 'startseq The white backdrop showcases a white vinyl that is minimally affected by both contamination and mild damage. endseq', 'startseq Displayed on the white background is a white vinyl that exhibits only a low degree of contamination and bears gentle signs of damage. endseq']\n",
      "['startseq The visual field is characterized by the absence of objects, leaving only a white background. endseq', 'startseq In dimly lit surroundings, a contaminated white plastic surface can be seen. endseq', 'startseq A white plastic background, contaminated, is apparent in the dim light. endseq', 'startseq Under low light conditions, a tainted white plastic backdrop exists. endseq', 'startseq Dim lighting unveils the presence of a polluted white plastic background. endseq']\n",
      "['startseq Only a black background under bright lighting is present without any objects. endseq', \"startseq There's nothing but a black backdrop under intense illumination. endseq\", 'startseq Under the bright lights, only a black background can be seen, devoid of objects. endseq', 'startseq In low light, a polluted white plastic background can be observed. endseq', 'startseq A white plastic background, contaminated, is visible in the dim light. endseq']\n",
      "['startseq The sole presence is a black background illuminated by bright lighting, devoid of any objects. endseq', 'startseq The only thing here is a brightly lit black backdrop, with no objects in sight. endseq', 'startseq There is nothing else except a well-lit black background with no objects. endseq', 'startseq A black background under intense lighting is the only thing present, free from objects. endseq', 'startseq Only a black background, brilliantly illuminated, can be seen, with no objects around. endseq']\n",
      "['startseq Only a black background under bright lighting is present without any objects. endseq', 'startseq Under the glare of bright lights, there is nothing except a black background. endseq', 'startseq In the well-lit space, only a black backdrop is present, with no objects. endseq', 'startseq Nothing but a black background can be observed under the bright lighting. endseq', 'startseq Under intense illumination, there exists solely a black background, void of objects. endseq']\n",
      "['startseq A transparent plastic drink cup lid is in good condition on the white background. endseq', 'startseq In prime condition, a see-through plastic lid for a drink cup is situated against a clean white background. endseq', 'startseq On the white surface, an intact transparent plastic cup lid is positioned, showcasing its flawless state. endseq', 'startseq A well-preserved plastic lid for a beverage cup, completely transparent, contrasts beautifully with the white background. endseq', 'startseq Resting on the pristine white backdrop, an unblemished clear plastic drink cup lid remains in excellent shape. endseq']\n",
      "['startseq A transparent plastic drink container and a transparent plastic drink lid are combined together on the white background. endseq', 'startseq Resting against the clean white surface, a transparent plastic drink container and its matching transparent plastic drink lid are elegantly paired. endseq', \"startseq Positioned on the white background, you'll see a seamless fusion of a transparent plastic drink container and its corresponding transparent plastic drink lid. endseq\", 'startseq The white backdrop showcases the union of a transparent plastic drink container and an accompanying transparent plastic drink lid, brought together harmoniously. endseq', 'startseq Displayed on the white background is a cohesive combination of a transparent plastic drink container and its perfectly fitting transparent plastic drink lid. endseq']\n",
      "['startseq Only a black background is visible in this setup, accentuated by bright lighting and devoid of objects. endseq', \"startseq Under intense illumination, there's only a black background, void of objects. endseq\", 'startseq Only a black background is in view under the bright lights, with no objects present. endseq', \"startseq In the presence of bright lighting, there's nothing else but a black backdrop. endseq\", \"startseq There's only a black background, and no objects, under bright lighting. endseq\"]\n",
      "['startseq A paper with various colors printed on it is folded and placed on the white background. endseq', 'startseq Positioned on the white background is a folded paper adorned with a variety of printed colors. endseq', \"startseq Resting against the clean white surface, you'll find a paper with a multitude of colors printed on it, neatly folded. endseq\", 'startseq The white backdrop showcases a folded paper featuring diverse colors in its print. endseq', 'startseq Displayed on the white background is a paper that has been folded, its surface adorned with a range of printed colors. endseq']\n",
      "['startseq There is only a white background with no objects. endseq', 'startseq The solitary presence is the clear white backdrop. endseq', 'startseq Nothing else can be seen except the empty white background. endseq', 'startseq All that is evident is the undecorated white background. endseq', 'startseq Only the white background with no elements is in view. endseq']\n",
      "['startseq There is only a white background in a dark area. endseq', \"startseq There's merely a tainted white plastic backdrop to be found. endseq\", 'startseq The exclusive presence is a polluted white plastic backdrop. endseq', 'startseq There is only a white plastic background tainted by contamination. endseq', 'startseq Only a polluted white plastic backdrop is in existence. endseq']\n",
      "['startseq A white paper is crumlped on a black background endseq', 'startseq Resting against the dark expanse of the black background, a white paper is crumpled, creating a textural contrast. endseq', \"startseq Positioned on the black surface, you'll find a crumpled white paper that adds dimension to the composition. endseq\", 'startseq The black backdrop provides a dramatic setting for a crumpled white paper, offering an intriguing interplay of light and shadow. endseq', 'startseq Displayed on the black background is a white paper that has been artfully crumpled, introducing a tactile element to the scene. endseq']\n",
      "['startseq In the presence of bright lighting, the only thing visible is a black background without any objects. endseq', 'startseq In the presence of dim lighting, a polluted white plastic surface is evident. endseq', 'startseq A dimly lit area reveals a contaminated white plastic backdrop. endseq', 'startseq Under low illumination, there exists a tainted white plastic background. endseq', 'startseq A polluted white plastic background can be seen in the dim light. endseq']\n",
      "['startseq An orange paper cup holder with a damaged shape, a well-preserved transparent plastic drink container, a well-preserved transparent plastic drink lid, and an opaque plastic straw are present on the white background. endseq', 'startseq Resting on the white background, an orange paper cup holder with a distorted shape is accompanied by a transparent plastic drink container, a transparent plastic drink lid in good condition, and an opaque plastic straw. endseq', \"startseq Positioned against the clean white surface, you'll find an orange paper cup holder that has suffered damage to its shape, joined by a well-maintained transparent plastic drink container, a pristine transparent plastic drink lid, and an opaque plastic straw. endseq\", 'startseq The white backdrop showcases an orange paper cup holder that has been deformed, coexisting with a transparent plastic drink container, a well-preserved transparent plastic drink lid, and an opaque plastic straw. endseq', 'startseq Displayed on the white background is an orange paper cup holder displaying a damaged form, alongside a carefully preserved transparent plastic drink container, a transparent plastic drink lid in great condition, and an opaque plastic straw. endseq']\n",
      "['startseq Only a black background is present with bright lighting. endseq', 'startseq Under the subdued glow, there exists a tainted white plastic backdrop. endseq', 'startseq In dim lighting conditions, a contaminated white plastic surface is present. endseq', 'startseq A tainted white plastic background becomes apparent under low light. endseq', 'startseq Under the dimly lit environment, a contaminated white plastic backdrop exists. endseq']\n",
      "['startseq Bright lighting reveals only a black background with no accompanying objects. endseq', 'startseq The space is characterized by a single white backdrop with no objects present. endseq', 'startseq The boundaries of the space are clearly demarcated by a solitary white background. endseq', 'startseq A solitary white backdrop defines the space entirely, without any objects. endseq', 'startseq The space is distinctly outlined by a white background devoid of objects. endseq']\n",
      "[\"startseq No objects occupy the frame; instead, there's just a plain white background. endseq\", 'startseq All that can be gazed upon is the empty white background. endseq', 'startseq Only the uncluttered white backdrop is visible. endseq', 'startseq The solitary view is the basic white background. endseq', 'startseq Nothing else is discernible except the empty white background. endseq']\n",
      "['startseq A contaminated white plastic background exists under dim lighting. endseq', \"startseq There's merely a tainted white plastic backdrop. endseq\", 'startseq The exclusive presence is a polluted white plastic background. endseq', 'startseq There is but a contaminated white plastic background. endseq', 'startseq Solely a tainted white plastic surface is present. endseq']\n",
      "['startseq A contaminated white plastic cup lid is on the white background. endseq', 'startseq The white background hosts a tainted plastic cup lid. endseq', 'startseq Against the backdrop of white, there sits a polluted plastic cup lid. endseq', 'startseq Resting on the white surface, a compromised plastic cup lid is displayed. endseq', 'startseq A white plastic cup lid, marred by contamination, occupies the scene. endseq']\n",
      "['startseq Due to dim lighting, the contaminated white plastic background appears gray. endseq', 'startseq A tainted white plastic backdrop is the exclusive presence. endseq', 'startseq There is but a polluted white plastic background. endseq', 'startseq Solely a contaminated white plastic surface is in sight. endseq', 'startseq A polluted white plastic background is the singular entity. endseq']\n",
      "['startseq The space is defined by a solitary white background without objects. endseq', 'startseq A lone white background shapes the space, devoid of objects. endseq', 'startseq The area is delineated by a single white backdrop with no objects. endseq', 'startseq Only a single white background occupies the space, free of objects. endseq', 'startseq The spatial boundaries are marked by a solitary white background without any objects. endseq']\n",
      "['startseq A white vinyl with brown letters printed on it is crumpled on the white background. endseq', 'startseq Positioned on the white background, a crumpled white vinyl featuring brown printed letters is displayed. endseq', \"startseq Resting against the clean white surface, you'll find a white vinyl adorned with letters in brown print, now crumpled. endseq\", 'startseq The white backdrop showcases a white vinyl with brown letters printed on it, its surface crumpled. endseq', 'startseq Displayed on the white background is a crumpled white vinyl bearing printed brown letters. endseq']\n",
      "['startseq The sole presence in this scene is a black background, illuminated by bright lighting, with an absence of objects. endseq', 'startseq Only a black background can be observed under the bright lighting, with no objects. endseq', \"startseq Under the intense lighting conditions, there's solely a black background. endseq\", 'startseq Only a black background is visible, and no objects, under the bright lights. endseq', \"startseq In the presence of bright lighting, there's nothing else but a black backdrop. endseq\"]\n",
      "['startseq The backdrop is purely white, without any objects. endseq', \"startseq There's just a polluted white plastic background to be seen. endseq\", 'startseq Only a contaminated white plastic backdrop is in sight. endseq', 'startseq A tainted white plastic backdrop is the exclusive sight. endseq', 'startseq There is but a polluted white plastic background to be found. endseq']\n",
      "['startseq An uncontaminated white paper cup is on the white background, and a paper cup holder with green text and an illustration printed on a brown background is well-preserved, with both objects combined. endseq', 'startseq On the pristine white surface, an unspoiled white paper cup is accompanied by a meticulously preserved paper cup holder. The holder showcases vivid green text and an illustration, presented against a deep brown background. endseq', 'startseq A flawless white paper cup graces the white background, seamlessly integrated with a carefully maintained paper cup holder. This holder displays lively green text and an illustration on a tasteful brown backdrop. endseq', 'startseq Resting on the pure white canvas, an immaculate white paper cup is paired with a well-kept paper cup holder. The holder boasts vibrant green text and an illustration, all printed against a sophisticated brown background. endseq', 'startseq An untouched white paper cup finds its place on the white background, united harmoniously with an impeccably conserved paper cup holder. This holder exhibits text in a lively green hue and an illustration on a backdrop of refined brown. endseq']\n"
     ]
    }
   ],
   "source": [
    "train_descriptions={}\n",
    "\n",
    "image_names = list(train_image_paths)\n",
    "test_image_names = list(test_image_paths)\n",
    "\n",
    "for i in range(0, len(train_image_paths)):\n",
    "  image_name = image_names[i].decode('utf-8')\n",
    "  caption_list = image_caption_map[image_name]\n",
    "  desc=[]\n",
    "  for caption in caption_list:\n",
    "    desc.append(f'startseq {caption} endseq')\n",
    "  train_descriptions[image_name] = desc\n",
    "  print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(descriptions,image_paths, images, word_to_index, max_length, num_images_per_batch ):\n",
    "  x1, x2, y = [], [], []\n",
    "  n=0\n",
    "  image_names = list(image_paths)\n",
    "  np.random.shuffle(image_names)\n",
    "  while True:\n",
    "    for j in range(9):\n",
    "      n+=1\n",
    "      image_name = image_names[j].decode('utf-8')\n",
    "      caption_list = descriptions[image_name]\n",
    "      image = images[image_paths.index(b''+image_name.encode())]\n",
    "\n",
    "      for desc in caption_list:\n",
    "        seq = [word_to_index[word] for word in desc.split(' ') if word in word_to_index]\n",
    "        for i in range(1, len(seq)):\n",
    "          in_seq, out_seq = seq[:i], seq[i]\n",
    "          in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "          out_seq = to_categorical([out_seq], num_classes=vocabulary_size)[0]\n",
    "          x1.append(image)\n",
    "          x2.append(in_seq)\n",
    "          y.append(out_seq)\n",
    "      if n == num_images_per_batch:\n",
    "        yield ([np.array(x1), np.array(x2)], np.array(y))\n",
    "        x1, x2, y = [],[],[]\n",
    "        n=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector, Concatenate, Activation, Flatten\n",
    "from keras.layers import Concatenate\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_images_per_batch = 3\n",
    "steps = len(train_descriptions) // number_images_per_batch\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# 이미지 모델 정의\n",
    "image_model = Sequential()\n",
    "image_model.add(Dense(256, input_dim=4096, activation='relu'))\n",
    "\n",
    "image_model.add(RepeatVector(max_words))\n",
    "\n",
    "# 언어 모델 정의\n",
    "lang_model = Sequential()\n",
    "lang_model.add(Embedding(vocabulary_size, 256, input_length=max_words))\n",
    "lang_model.add(LSTM(512, return_sequences=True))\n",
    "lang_model.add(TimeDistributed(Dense(128)))\n",
    "\n",
    "# 두 모델 합치기\n",
    "model = Sequential()\n",
    "merged = Concatenate()([image_model.output, lang_model.output])\n",
    "lstm_layer = LSTM(1000, return_sequences=False)(merged)\n",
    "output_layer = Dense(vocabulary_size, activation='softmax')(lstm_layer)\n",
    "model = Model(inputs=[image_model.input, lang_model.input], outputs=output_layer)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# 조기 종료 콜백 정의 (검증 데이터 손실을 모니터링)\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " embedding_input (InputLayer)   [(None, 46)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_input (InputLayer)       [(None, 4096)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 46, 256)      204288      ['embedding_input[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          1048832     ['dense_input[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 46, 512)      1574912     ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 46, 256)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 46, 128)     65664       ['lstm[0][0]']                   \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 46, 384)      0           ['repeat_vector[0][0]',          \n",
      "                                                                  'time_distributed[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 1000)         5540000     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 798)          798798      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,232,494\n",
      "Trainable params: 9,232,494\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]C:\\Users\\wkwhs\\AppData\\Local\\Temp\\ipykernel_18600\\3939439051.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(data_generator(train_descriptions, train_image_paths ,train_ds, word_to_index_map, max_words, number_images_per_batch),epochs=1,steps_per_epoch=steps, verbose=1)\n",
      "c:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/40 [=>............................] - ETA: 3:58 - loss: 6.5859 - accuracy: 0.0088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m EPOCHS\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(EPOCHS)):\n\u001b[1;32m----> 4\u001b[0m   model\u001b[39m.\u001b[39;49mfit_generator(data_generator(train_descriptions, train_image_paths ,train_ds, word_to_index_map, max_words, number_images_per_batch),epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,steps_per_epoch\u001b[39m=\u001b[39;49msteps, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:2636\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2624\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2625\u001b[0m \n\u001b[0;32m   2626\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2627\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[0;32m   2628\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[0;32m   2629\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2630\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2631\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2632\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2633\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2634\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2635\u001b[0m )\n\u001b[1;32m-> 2636\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   2637\u001b[0m     generator,\n\u001b[0;32m   2638\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   2639\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   2640\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2641\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   2642\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   2643\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   2644\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   2645\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2646\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2647\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2648\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2649\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   2650\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m   2651\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1284\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_function\u001b[39m(iterator):\n\u001b[0;32m   1283\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1284\u001b[0m     \u001b[39mreturn\u001b[39;00m step_function(\u001b[39mself\u001b[39;49m, iterator)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1268\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1264\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1265\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m     )\n\u001b[0;32m   1267\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1268\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1269\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1270\u001b[0m     outputs,\n\u001b[0;32m   1271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1272\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1273\u001b[0m )\n\u001b[0;32m   1274\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1312\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1314\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1315\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2893\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2894\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2895\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3694\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3695\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3696\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    594\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 595\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1249\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1249\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1250\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1050\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[39m# Run forward pass.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m-> 1050\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1051\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m   1052\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:558\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    556\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 558\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1144\u001b[0m ):\n\u001b[1;32m-> 1145\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\functional.py:512\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    495\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \n\u001b[0;32m    497\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\functional.py:669\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    666\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 669\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    671\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    673\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[0;32m    674\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[0;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[0;32m    553\u001b[0m )\n\u001b[0;32m    555\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    558\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[0;32m    562\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\base_layer.py:1145\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1142\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1144\u001b[0m ):\n\u001b[1;32m-> 1145\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\layers\\rnn\\lstm.py:740\u001b[0m, in \u001b[0;36mLSTM.call\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    730\u001b[0m         last_output, outputs, new_h, new_c, runtime \u001b[39m=\u001b[39m gpu_lstm(\n\u001b[0;32m    731\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgpu_lstm_kwargs\n\u001b[0;32m    732\u001b[0m         )\n\u001b[0;32m    733\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    734\u001b[0m         (\n\u001b[0;32m    735\u001b[0m             last_output,\n\u001b[0;32m    736\u001b[0m             outputs,\n\u001b[0;32m    737\u001b[0m             new_h,\n\u001b[0;32m    738\u001b[0m             new_c,\n\u001b[0;32m    739\u001b[0m             runtime,\n\u001b[1;32m--> 740\u001b[0m         ) \u001b[39m=\u001b[39m standard_lstm(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnormal_lstm_kwargs)\n\u001b[0;32m    741\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    742\u001b[0m     (\n\u001b[0;32m    743\u001b[0m         last_output,\n\u001b[0;32m    744\u001b[0m         outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    747\u001b[0m         runtime,\n\u001b[0;32m    748\u001b[0m     ) \u001b[39m=\u001b[39m lstm_with_backend_selection(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnormal_lstm_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\layers\\rnn\\lstm.py:980\u001b[0m, in \u001b[0;36mstandard_lstm\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[0;32m    977\u001b[0m     h \u001b[39m=\u001b[39m o \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mtanh(c)\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m h, [h, c]\n\u001b[1;32m--> 980\u001b[0m last_output, outputs, new_states \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mrnn(\n\u001b[0;32m    981\u001b[0m     step,\n\u001b[0;32m    982\u001b[0m     inputs,\n\u001b[0;32m    983\u001b[0m     [init_h, init_c],\n\u001b[0;32m    984\u001b[0m     constants\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    985\u001b[0m     unroll\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    986\u001b[0m     time_major\u001b[39m=\u001b[39;49mtime_major,\n\u001b[0;32m    987\u001b[0m     mask\u001b[39m=\u001b[39;49mmask,\n\u001b[0;32m    988\u001b[0m     go_backwards\u001b[39m=\u001b[39;49mgo_backwards,\n\u001b[0;32m    989\u001b[0m     input_length\u001b[39m=\u001b[39;49m(\n\u001b[0;32m    990\u001b[0m         sequence_lengths \u001b[39mif\u001b[39;49;00m sequence_lengths \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m timesteps\n\u001b[0;32m    991\u001b[0m     ),\n\u001b[0;32m    992\u001b[0m     zero_output_for_mask\u001b[39m=\u001b[39;49mzero_output_for_mask,\n\u001b[0;32m    993\u001b[0m     return_all_outputs\u001b[39m=\u001b[39;49mreturn_sequences,\n\u001b[0;32m    994\u001b[0m )\n\u001b[0;32m    995\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    996\u001b[0m     last_output,\n\u001b[0;32m    997\u001b[0m     outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     gru_lstm_utils\u001b[39m.\u001b[39mruntime(gru_lstm_utils\u001b[39m.\u001b[39mRUNTIME_CPU),\n\u001b[0;32m   1001\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py:5169\u001b[0m, in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[0;32m   5164\u001b[0m         new_states \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   5165\u001b[0m             initial_states, flat_new_state\n\u001b[0;32m   5166\u001b[0m         )\n\u001b[0;32m   5167\u001b[0m         \u001b[39mreturn\u001b[39;00m (time \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, output_ta_t) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(new_states)\n\u001b[1;32m-> 5169\u001b[0m     final_outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[0;32m   5170\u001b[0m         body\u001b[39m=\u001b[39;49m_step,\n\u001b[0;32m   5171\u001b[0m         loop_vars\u001b[39m=\u001b[39;49m(time, output_ta) \u001b[39m+\u001b[39;49m states,\n\u001b[0;32m   5172\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mwhile_loop_kwargs,\n\u001b[0;32m   5173\u001b[0m     )\n\u001b[0;32m   5174\u001b[0m     new_states \u001b[39m=\u001b[39m final_outputs[\u001b[39m2\u001b[39m:]\n\u001b[0;32m   5176\u001b[0m output_ta \u001b[39m=\u001b[39m final_outputs[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:2823\u001b[0m, in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2820\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[0;32m   2821\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[0;32m   2822\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39mloop_vars):\n\u001b[1;32m-> 2823\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39;49mloop_vars)\n\u001b[0;32m   2824\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, _basetuple)):\n\u001b[0;32m   2825\u001b[0m     packed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py:5148\u001b[0m, in \u001b[0;36mrnn.<locals>._step\u001b[1;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[0;32m   5146\u001b[0m current_input \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ta\u001b[39m.\u001b[39mread(time) \u001b[39mfor\u001b[39;00m ta \u001b[39min\u001b[39;00m input_ta)\n\u001b[0;32m   5147\u001b[0m current_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(inputs, current_input)\n\u001b[1;32m-> 5148\u001b[0m output, new_states \u001b[39m=\u001b[39m step_function(\n\u001b[0;32m   5149\u001b[0m     current_input, \u001b[39mtuple\u001b[39;49m(states) \u001b[39m+\u001b[39;49m \u001b[39mtuple\u001b[39;49m(constants)\n\u001b[0;32m   5150\u001b[0m )\n\u001b[0;32m   5151\u001b[0m flat_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(states)\n\u001b[0;32m   5152\u001b[0m flat_new_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(new_states)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\layers\\rnn\\lstm.py:974\u001b[0m, in \u001b[0;36mstandard_lstm.<locals>.step\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m    972\u001b[0m i \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msigmoid(z0)\n\u001b[0;32m    973\u001b[0m f \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msigmoid(z1)\n\u001b[1;32m--> 974\u001b[0m c \u001b[39m=\u001b[39m f \u001b[39m*\u001b[39;49m c_tm1 \u001b[39m+\u001b[39m i \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mtanh(z2)\n\u001b[0;32m    975\u001b[0m o \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msigmoid(z3)\n\u001b[0;32m    977\u001b[0m h \u001b[39m=\u001b[39m o \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39mtanh(c)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1459\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1455\u001b[0m   \u001b[39m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1457\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1458\u001b[0m   x, y \u001b[39m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[1;32m-> 1459\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1460\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1461\u001b[0m   \u001b[39m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m   \u001b[39m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1465\u001b[0m   \u001b[39m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m   \u001b[39m# informative.\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39m__r\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m op_name):\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1819\u001b[0m, in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1817\u001b[0m   \u001b[39mreturn\u001b[39;00m sparse_tensor\u001b[39m.\u001b[39mSparseTensor(y\u001b[39m.\u001b[39mindices, new_vals, y\u001b[39m.\u001b[39mdense_shape)\n\u001b[0;32m   1818\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1819\u001b[0m   \u001b[39mreturn\u001b[39;00m multiply(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:530\u001b[0m, in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.multiply\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultiply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    482\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39mregister_binary_elementwise_api\n\u001b[0;32m    483\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmultiply\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    485\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns an element-wise x * y.\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \n\u001b[0;32m    487\u001b[0m \u001b[39m  For example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[39m   * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmul(x, y, name)\n",
      "File \u001b[1;32mc:\\Users\\wkwhs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:7324\u001b[0m, in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   7322\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   7323\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 7324\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   7325\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMul\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, x, y)\n\u001b[0;32m   7326\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   7327\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_fit = data_generator(train_descriptions, train_image_paths ,train_ds, word_to_index_map, max_words, number_images_per_batch)\n",
    "\n",
    "for i in tqdm(range(EPOCHS)):\n",
    "  model.fit_generator(train_fit, epochs = 50, steps_per_epoch = steps, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../img_test_08/imagecaption.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCaption(image):\n",
    "    in_text = 'startseq'\n",
    "    for i in range(max_words):\n",
    "        sequence = [word_to_index_map[w] for w in in_text.split() if w in word_to_index_map.keys()]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_words)\n",
    "        yhat = model.predict([image, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = index_to_word_map[yhat]\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 반복 단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_caption(caption):\n",
    "    # 소문자로 변환\n",
    "    caption = caption.lower()\n",
    "\n",
    "    # 문장을 단어로 토큰화\n",
    "    words = word_tokenize(caption)\n",
    "\n",
    "    # 불용어(stopword) 제거\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    # 중복 단어 제거\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "\n",
    "    # 정제된 단어들을 다시 문장으로 결합\n",
    "    cleaned_caption = ' '.join(unique_words)\n",
    "\n",
    "    # 시작 및 끝 토큰 추가\n",
    "    cleaned_caption = cleaned_caption + ' endseq'\n",
    "\n",
    "    return cleaned_caption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 및 캡션 결과 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "  z = z = random.randint(0, len(test_ds) - 1)\n",
    "  image_name = test_image_paths[z].decode('utf-8')  # 이미지 파일 이름 가져오기\n",
    "  image = test_ds[z]\n",
    "  image = image.reshape((1, 4096))\n",
    "\n",
    "  image_path = os.path.join('../img_test_08/AI_Result_img', image_name)\n",
    "\n",
    "  # 이미지 파일을 PIL 모듈을 사용하여 열고 변환\n",
    "  pil_image = Image.open(image_path)\n",
    "\n",
    "  plt.imshow(pil_image)  # 이미지를 바로 표시\n",
    "  plt.show()\n",
    "  caption_Re = generateCaption(image)\n",
    "  for caption in captions:\n",
    "    cleaned_caption = preprocess_caption(caption_Re)\n",
    "  print(\"Caption:\", cleaned_caption)\n",
    "  print(\"--------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
